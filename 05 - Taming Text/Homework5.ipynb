{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import nltk\n",
    "from scipy.stats import itemfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_directory = 'hillary-clinton-emails/'\n",
    "df = pd.read_csv(current_directory + 'Emails.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Word Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate word cloud without preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use package `word_cloud` to generate a word cloud. The text are from the extracted columns of this dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# random_corpus = (df.iloc[np.random.choice(df.index, size=2000, replace=False), -2].dropna()).sum()\n",
    "all_body_text = (df.loc[:, 'ExtractedBodyText'].dropna()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(max_font_size=40).generate(all_body_text)\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate word cloud with preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Strategies\n",
    "\n",
    "1. filter out some email word like `fw`, `fwd`, `subject` and so on\n",
    "2. case folding: reduce all letters to lower case\n",
    "3. ignoring punctuates\n",
    "\n",
    "TODO: (maybe)\n",
    "\n",
    "1. Try Lemmatization\n",
    "2. Try Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans({key: '' for key in string.punctuation}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "email_word_list = ['fw', 'fwd', 'subject', 'to', 're', 'pm', 'will', 'case', 'also', 're', 'call', 'may', 'mr', 'ms', 'mrs']\n",
    "stopwords = set(email_word_list).union(set(STOPWORDS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Processing words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Concatenate all the Extracted Body Text\n",
    "txt = (df.loc[:, 'ExtractedBodyText'].dropna()).sum()\n",
    "txt = remove_punctuation(txt)\n",
    "tokens = nltk.word_tokenize(txt)\n",
    "tokens = [i.lower() for i in tokens if i.lower() not in stopwords]\n",
    "tokens_freq = itemfreq(tokens)\n",
    "tokens, tokens_freq = tokens_freq[:, 0], tokens_freq[:, 1].astype(int)\n",
    "tokens_x_freq = [(tokens[i], tokens_freq[i]) for i in range(len(tokens))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(max_font_size=40, stopwords=STOPWORDS).generate_from_frequencies(tokens_x_freq)\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "\n",
    "pt = PorterStemmer()\n",
    "text = 'Clarissa risca com giz no quadro-negro a paisagem que os alunos devem copiar . Uma casinha de porta e janela , em cima duma coxilha .'\n",
    "for token in text.split():\n",
    "    print(pt.stem(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pt = SnowballStemmer('english')\n",
    "def compare_stem(word1, word2):\n",
    "    \"\"\"if two words have same \"\"\"\n",
    "    print(pt.stem(word1))\n",
    "    print(pt.stem(word2))\n",
    "    return pt.stem(word1) ==  pt.stem(word2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
